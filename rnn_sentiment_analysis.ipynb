{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "df = pd.read_csv('your_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values in the 'text' column\n",
    "# if needed\n",
    "# comment this is not needed\n",
    "df['text'].fillna(\"\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(df['text'])\n",
    "sequences = tokenizer.texts_to_sequences(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding sequences\n",
    "X = pad_sequences(sequences, maxlen=100, padding='post', truncating='post')\n",
    "\n",
    "# Assuming 'sentiment_numerical' is the target variable\n",
    "y = df['sentiment_numerical']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change values to perform hyperparameter tuning\n",
    "EPOCHS = 20\n",
    "BTH_SIZE= 35\n",
    "VAL_SPLIT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=5000, output_dim=64, input_length=100))\n",
    "model.add(Bidirectional(LSTM(25, kernel_regularizer='l2')))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu', kernel_regularizer='l2'))  # L2 regularization\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax', kernel_initializer='he_normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BTH_SIZE,\n",
    "    validation_split=VAL_SPLIT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the test set\n",
    "print(\"\\nTest Accuracy\")\n",
    "print(model.evaluate(X_test, y_test)[1])\n",
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy and loss curves\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(EPOCHS), acc, label=' Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Accuracy')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(EPOCHS), loss, label=' Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save('rnn_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code cell will extract a random text and perform a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model for random text prediction\n",
    "model = load_model('improved_rnn_model.h5')\n",
    "\n",
    "# Assuming 'text' is the column containing the text data\n",
    "texts = df['text']\n",
    "sentiments = df['sentiment']  # Assuming 'sentiment' is the column containing the sentiment labels\n",
    "\n",
    "# Choose a random index\n",
    "random_index = np.random.randint(0, len(texts))\n",
    "\n",
    "# Get the text and original sentiment at the random index\n",
    "random_text = texts.iloc[random_index]\n",
    "original_sentiment = sentiments.iloc[random_index]\n",
    "\n",
    "# Preprocess the random text\n",
    "sequence = tokenizer.texts_to_sequences([random_text])\n",
    "padded_sequence = pad_sequences(sequence, maxlen=100, padding='post', truncating='post')\n",
    "\n",
    "# Make a prediction\n",
    "predictions = model.predict(padded_sequence)\n",
    "\n",
    "# Get the predicted sentiment\n",
    "predicted_sentiment = predictions.argmax()\n",
    "\n",
    "print(\"Sentiment numeric labels: 0 = negative, 1 = neutral, 2 = positive\")\n",
    "print(f\"Random Text: {random_text}\")\n",
    "print(f\"Original Sentiment: {original_sentiment}\")\n",
    "print(f\"Predicted Sentiment: {predicted_sentiment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code cell will enable the user to give an input and model will perform a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the trained model for random text prediction\n",
    "model = load_model('improved_rnn_model.h5')\n",
    "\n",
    "# Take user input for the text\n",
    "user_text = input(\"Enter the text: \")\n",
    "\n",
    "# Preprocess the user input\n",
    "sequence = tokenizer.texts_to_sequences([user_text])\n",
    "padded_sequence = pad_sequences(sequence, maxlen=100, padding='post', truncating='post')\n",
    "\n",
    "# Make a prediction\n",
    "predictions = model.predict(padded_sequence)\n",
    "\n",
    "# Get the predicted sentiment\n",
    "predicted_sentiment = predictions.argmax()\n",
    "\n",
    "print(\"Sentiment numeric labels: 0 = negative, 1 = neutral, 2 = positive\")\n",
    "print(f\"User Input Text: {user_text}\")\n",
    "print(f\"Predicted Sentiment: {predicted_sentiment}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
